{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cc56584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee09c4",
   "metadata": {},
   "source": [
    "Import the data to add zipcode information for home, trip origin, and trip destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "712db0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Georgia\n",
    "trip_GA = pd.read_csv('../Data/2017-tsdc-nhts-georgia-add-on-download/data/survey_trip.csv')\n",
    "loc_GA = pd.read_csv('../Data/2017-tsdc-nhts-georgia-add-on-download/data/survey_location.csv')\n",
    "per_GA = pd.read_csv('../Data/2017-tsdc-nhts-georgia-add-on-download/data/survey_person.csv')\n",
    "hh_GA = pd.read_csv('../Data/2017-tsdc-nhts-georgia-add-on-download/data/survey_household.csv')\n",
    "veh_GA = pd.read_csv('../Data/2017-tsdc-nhts-georgia-add-on-download/data/survey_vehicle.csv')\n",
    "hh_wgt_GA = pd.read_csv('../Data/2017-tsdc-nhts-georgia-add-on-download/data/weights_household_7day.csv')\n",
    "\n",
    "loc_GA['idx'] = loc_GA['sampno'] + loc_GA['locno']/10**7\n",
    "loc_GA = loc_GA.set_index('idx')['zipcode']\n",
    "trip_GA['o_idx'] = trip_GA['sampno'] + trip_GA['o_locno']/10**7\n",
    "trip_GA['d_idx'] = trip_GA['sampno'] + trip_GA['locno']/10**7\n",
    "trip_GA['o_zip'] = trip_GA.o_idx.map(loc_GA)\n",
    "trip_GA['d_zip'] = trip_GA.d_idx.map(loc_GA)\n",
    "\n",
    "# INCOG - Oklahoma\n",
    "trip_OK = pd.read_csv('../Data/2017-tsdc-nhts-incog-add-on-download/data/survey_trip.csv')\n",
    "loc_OK = pd.read_csv('../Data/2017-tsdc-nhts-incog-add-on-download/data/survey_location.csv')\n",
    "per_OK = pd.read_csv('../Data/2017-tsdc-nhts-incog-add-on-download/data/survey_person.csv')\n",
    "hh_OK = pd.read_csv('../Data/2017-tsdc-nhts-incog-add-on-download/data/survey_household.csv')\n",
    "veh_OK = pd.read_csv('../Data/2017-tsdc-nhts-incog-add-on-download/data/survey_vehicle.csv')\n",
    "hh_wgt_OK = pd.read_csv('../Data/2017-tsdc-nhts-incog-add-on-download/data/weights_household_7day.csv')\n",
    "\n",
    "loc_OK['idx'] = loc_OK['sampno'] + loc_OK['locno']/10**7\n",
    "loc_OK = loc_OK.set_index('idx')['zipcode']\n",
    "trip_OK['o_idx'] = trip_OK['sampno'] + trip_OK['o_locno']/10**7\n",
    "trip_OK['d_idx'] = trip_OK['sampno'] + trip_OK['locno']/10**7\n",
    "trip_OK['o_zip'] = trip_OK.o_idx.map(loc_OK)\n",
    "trip_OK['d_zip'] = trip_OK.d_idx.map(loc_OK)\n",
    "\n",
    "# Iowa\n",
    "trip_IA = pd.read_csv('../Data/2017-tsdc-nhts-iowa-add-on-download/data/survey_trip.csv')\n",
    "loc_IA = pd.read_csv('../Data/2017-tsdc-nhts-iowa-add-on-download/data/survey_location.csv')\n",
    "per_IA = pd.read_csv('../Data/2017-tsdc-nhts-iowa-add-on-download/data/survey_person.csv')\n",
    "hh_IA = pd.read_csv('../Data/2017-tsdc-nhts-iowa-add-on-download/data/survey_household.csv')\n",
    "veh_IA = pd.read_csv('../Data/2017-tsdc-nhts-iowa-add-on-download/data/survey_vehicle.csv')\n",
    "hh_wgt_IA = pd.read_csv('../Data/2017-tsdc-nhts-iowa-add-on-download/data/survey_household_weights_7day.csv')\n",
    "\n",
    "loc_IA['idx'] = loc_IA['sampno'] + loc_IA['locno']/10**7\n",
    "loc_IA = loc_IA.set_index('idx')['zipcode']\n",
    "trip_IA['o_idx'] = trip_IA['sampno'] + trip_IA['o_locno']/10**7\n",
    "trip_IA['d_idx'] = trip_IA['sampno'] + trip_IA['locno']/10**7\n",
    "trip_IA['o_zip'] = trip_IA.o_idx.map(loc_IA)\n",
    "trip_IA['d_zip'] = trip_IA.d_idx.map(loc_IA)\n",
    "\n",
    "# California\n",
    "trip_CA = pd.read_csv('../Data/nhts17-caltrans-tsdc-download/data/survey_trip.csv')\n",
    "loc_CA = pd.read_csv('../Data/nhts17-caltrans-tsdc-download/data/survey_location.csv')\n",
    "per_CA = pd.read_csv('../Data/nhts17-caltrans-tsdc-download/data/survey_person.csv')\n",
    "hh_CA = pd.read_csv('../Data/nhts17-caltrans-tsdc-download/data/survey_household.csv')\n",
    "veh_CA = pd.read_csv('../Data/nhts17-caltrans-tsdc-download/data/survey_vehicle.csv')\n",
    "hh_wgt_CA = pd.read_csv('../Data/nhts17-caltrans-tsdc-download/data/survey_household_weights_7day.csv')\n",
    "\n",
    "loc_CA['idx'] = loc_CA['sampno'] + loc_CA['locno']/10**7\n",
    "loc_CA = loc_CA.set_index('idx')['zipcode']\n",
    "trip_CA['o_idx'] = trip_CA['sampno'] + trip_CA['o_locno']/10**7\n",
    "trip_CA['d_idx'] = trip_CA['sampno'] + trip_CA['locno']/10**7\n",
    "trip_CA['o_zip'] = trip_CA.o_idx.map(loc_CA)\n",
    "trip_CA['d_zip'] = trip_CA.d_idx.map(loc_CA)\n",
    "\n",
    "# Arizona\n",
    "trip_AZ = pd.read_csv('../Data/nhts-azdot-17/data/survey_trip.csv')\n",
    "loc_AZ = pd.read_csv('../Data/nhts-azdot-17/data/survey_location.csv')\n",
    "per_AZ = pd.read_csv('../Data/nhts-azdot-17/data/survey_person.csv')\n",
    "hh_AZ = pd.read_csv('../Data/nhts-azdot-17/data/survey_household.csv')\n",
    "veh_AZ = pd.read_csv('../Data/nhts-azdot-17/data/survey_vehicle.csv')\n",
    "hh_wgt_AZ = pd.read_csv('../Data/nhts-azdot-17/data/survey_household_weights_7day.csv')\n",
    "\n",
    "loc_AZ['idx'] = loc_AZ['sampno'] + loc_AZ['locno']/10**7\n",
    "loc_AZ = loc_AZ.set_index('idx')['zipcode']\n",
    "trip_AZ['o_idx'] = trip_AZ['sampno'] + trip_AZ['o_locno']/10**7\n",
    "trip_AZ['d_idx'] = trip_AZ['sampno'] + trip_AZ['locno']/10**7\n",
    "trip_AZ['o_zip'] = trip_AZ.o_idx.map(loc_AZ)\n",
    "trip_AZ['d_zip'] = trip_AZ.d_idx.map(loc_AZ)\n",
    "\n",
    "# Wisconsin\n",
    "trip_WI = pd.read_csv('../Data/tsdc-nhts-2017-wisconsin-add-on-download/data/survey_trip.csv')\n",
    "loc_WI = pd.read_csv('../Data/tsdc-nhts-2017-wisconsin-add-on-download/data/survey_location.csv')\n",
    "per_WI = pd.read_csv('../Data/tsdc-nhts-2017-wisconsin-add-on-download/data/survey_person.csv')\n",
    "hh_WI = pd.read_csv('../Data/tsdc-nhts-2017-wisconsin-add-on-download/data/survey_household.csv')\n",
    "veh_WI = pd.read_csv('../Data/tsdc-nhts-2017-wisconsin-add-on-download/data/survey_vehicle.csv')\n",
    "hh_wgt_WI = pd.read_csv('../Data/tsdc-nhts-2017-wisconsin-add-on-download/data/weights_household_7day.csv')\n",
    "\n",
    "loc_WI['idx'] = loc_WI['sampno'] + loc_WI['locno']/10**7\n",
    "loc_WI = loc_WI.set_index('idx')['zipcode']\n",
    "trip_WI['o_idx'] = trip_WI['sampno'] + trip_WI['o_locno']/10**7\n",
    "trip_WI['d_idx'] = trip_WI['sampno'] + trip_WI['locno']/10**7\n",
    "trip_WI['o_zip'] = trip_WI.o_idx.map(loc_WI)\n",
    "trip_WI['d_zip'] = trip_WI.d_idx.map(loc_WI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c918d",
   "metadata": {},
   "source": [
    "Remove records with missing zipcodes for origin and/or destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e503af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_GA = trip_GA[(trip_GA.o_zip!=\"-1\") & (trip_GA.d_zip!=\"-1\")]\n",
    "trip_OK = trip_OK[(trip_OK.o_zip!=\"-1\") & (trip_OK.d_zip!=\"-1\")]\n",
    "trip_IA = trip_IA[(trip_IA.o_zip!=\"-1\") & (trip_IA.d_zip!=\"-1\")]\n",
    "trip_CA = trip_CA[(trip_CA.o_zip!=\"-1\") & (trip_CA.d_zip!=\"-1\")]\n",
    "trip_AZ = trip_AZ[(trip_AZ.o_zip!=\"-1\") & (trip_AZ.d_zip!=\"-1\")]\n",
    "trip_WI = trip_WI[(trip_WI.o_zip!=\"-1\") & (trip_WI.d_zip!=\"-1\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e06a73c",
   "metadata": {},
   "source": [
    "Generate mode alternatives for trip table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b361d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_dict = {1:1,2:2,3:3,4:3,5:3,6:3,8:3,11:4,16:4,7:-1,9:-1,10:-1,12:-1,13:-1,14:-1,15:-1,17:-1,18:-1,19:-1,20:-1,97:-1}\n",
    "trip_GA['ch_mode'] = trip_GA.trptrans.map(mode_dict)\n",
    "trip_OK['ch_mode'] = trip_OK.trptrans.map(mode_dict)\n",
    "trip_IA['ch_mode'] = trip_IA.trptrans.map(mode_dict)\n",
    "trip_CA['ch_mode'] = trip_CA.trptrans.map(mode_dict)\n",
    "trip_AZ['ch_mode'] = trip_AZ.trptrans.map(mode_dict)\n",
    "trip_WI['ch_mode'] = trip_WI.trptrans.map(mode_dict)\n",
    "\n",
    "# Add NHTS dataset here to have larger dataset for training travel time prediction\n",
    "trip_USA = pd.read_csv('../Data/NHTS/trippub.csv')\n",
    "trip_USA['ch_mode'] = trip_USA.TRPTRANS.map(mode_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6dcf78",
   "metadata": {},
   "source": [
    "Predict travel times from travel distance by mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "802f8c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "regr_auto = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "est_data = trip_USA[(trip_USA.ch_mode==3)&(trip_USA.TRVLCMIN>0)]\n",
    "regr_auto.fit(est_data.TRPMILES.values.reshape(-1,1), est_data.TRVLCMIN.values)\n",
    "\n",
    "regr_transit_tott = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "est_data = trip_USA[(trip_USA.ch_mode==4)&(trip_USA.TRVLCMIN>0)]\n",
    "regr_transit_tott.fit(est_data.TRPMILES.values.reshape(-1,1), est_data.TRVLCMIN)\n",
    "\n",
    "regr_transit_acct = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "est_data = trip_USA[(trip_USA.ch_mode==4)&(trip_USA.TRACCTM>0)]\n",
    "regr_transit_acct.fit(est_data.TRPMILES.values.reshape(-1,1), est_data.TRACCTM)\n",
    "\n",
    "regr_transit_egrt = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "est_data = trip_USA[(trip_USA.ch_mode==4)&(trip_USA.TREGRTM>0)]\n",
    "regr_transit_egrt.fit(est_data.TRPMILES.values.reshape(-1,1), est_data.TREGRTM)\n",
    "\n",
    "regr_transit_waitt = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "est_data = trip_USA[(trip_USA.ch_mode==4)&(trip_USA.TRWAITTM>0)]\n",
    "regr_transit_waitt.fit(est_data.TRPMILES.values.reshape(-1,1), est_data.TRWAITTM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c02699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mode_alts(df,regr_auto,regr_transit_tott,regr_transit_acct,regr_transit_egrt,regr_transit_waitt):\n",
    "    df = df[df.ch_mode>0] # Only include records for walk, bike, private vehicle, bus transit, and rail transit modes\n",
    "    \n",
    "    # Imputed auto/transit values\n",
    "    df =  df.assign(imp_auto_time=regr_auto.predict(df.trpmiles.values.reshape(-1,1)),imp_transit_time=regr_transit_tott.predict(df.trpmiles.values.reshape(-1,1)),imp_access_time=regr_transit_acct.predict(df.trpmiles.values.reshape(-1,1)),imp_egress_time=regr_transit_egrt.predict(df.trpmiles.values.reshape(-1,1)),imp_wait_time=regr_transit_waitt.predict(df.trpmiles.values.reshape(-1,1)))\n",
    "    \n",
    "    # Walk mode\n",
    "    # Trip distance already given as TRPMILES\n",
    "    # Bike mode\n",
    "    # Trip distance already given as TRPMILES\n",
    "    # Private vehicle mode\n",
    "    df.loc[:,'auto_tt'] = np.where((df.ch_mode==3)&(df.trvlcmin>0),df.trvlcmin,df.imp_auto_time)\n",
    "    df.loc[:,'auto_cost'] = df.loc[:,'gasprice'] # use gas price per mile for auto cost\n",
    "    # Transit mode\n",
    "    df.loc[:,'transit_tt'] = np.where(df.ch_mode==4,df.trvlcmin,df.imp_transit_time)\n",
    "    df.loc[:,'transit_acct'] = np.where(df.ch_mode==4,df.trvlcmin,df.imp_access_time)\n",
    "    df.loc[:,'transit_egrt'] = np.where(df.ch_mode==4,df.trvlcmin,df.imp_egress_time)\n",
    "    df.loc[:,'transit_waitt'] = np.where(df.ch_mode==4,df.trwaittm,df.imp_wait_time)\n",
    "    # df['transit_cost'] = np.where(df.ch_mode==4,df.trvlcmin,df.imp_auto_time)\n",
    "    \n",
    "    # Don't allow negative numbers\n",
    "    df.loc[df.transit_waitt<0,['transit_waitt']] = df.loc[df.transit_waitt<0,['imp_wait_time']]\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecc2f144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When we merge the df, there may be duplicate sampno keys because they are not unique across datasets. Add an additional dataset indicator as a decimal\n",
    "trip_GA_mode = generate_mode_alts(trip_GA,regr_auto,regr_transit_tott,regr_transit_acct,regr_transit_egrt,regr_transit_waitt)\n",
    "trip_GA_mode[\"UID\"] = trip_GA_mode[\"sampno\"] + 0.1\n",
    "trip_OK_mode = generate_mode_alts(trip_OK,regr_auto,regr_transit_tott,regr_transit_acct,regr_transit_egrt,regr_transit_waitt)\n",
    "trip_OK_mode[\"UID\"] = trip_OK_mode[\"sampno\"] + 0.2\n",
    "trip_IA_mode = generate_mode_alts(trip_IA,regr_auto,regr_transit_tott,regr_transit_acct,regr_transit_egrt,regr_transit_waitt)\n",
    "trip_IA_mode[\"UID\"] = trip_IA_mode[\"sampno\"] + 0.3\n",
    "trip_CA_mode = generate_mode_alts(trip_CA,regr_auto,regr_transit_tott,regr_transit_acct,regr_transit_egrt,regr_transit_waitt)\n",
    "trip_CA_mode[\"UID\"] = trip_CA_mode[\"sampno\"] + 0.4\n",
    "trip_AZ_mode = generate_mode_alts(trip_AZ,regr_auto,regr_transit_tott,regr_transit_acct,regr_transit_egrt,regr_transit_waitt)\n",
    "trip_AZ_mode[\"UID\"] = trip_AZ_mode[\"sampno\"] + 0.5\n",
    "trip_WI_mode = generate_mode_alts(trip_WI,regr_auto,regr_transit_tott,regr_transit_acct,regr_transit_egrt,regr_transit_waitt)\n",
    "trip_WI_mode[\"UID\"] = trip_WI_mode[\"sampno\"] + 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26534f01-9235-493a-a7cc-9b446b0d64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_all = pd.concat([trip_GA_mode,trip_OK_mode,trip_IA_mode,trip_CA_mode,trip_AZ_mode,trip_WI_mode])\n",
    "\n",
    "trip_all.to_csv(\"../Data/trips_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55f50452-4245-49c4-bcaf-b765c15197ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_GA[\"UID\"] = per_GA[\"sampno\"] + 0.1\n",
    "hh_GA[\"UID\"] = hh_GA[\"sampno\"] + 0.1\n",
    "hh_wgt_GA[\"UID\"] = hh_wgt_GA[\"sampno\"] + 0.1\n",
    "veh_GA[\"UID\"] = veh_GA[\"sampno\"] + 0.1\n",
    "per_OK[\"UID\"] = per_OK[\"sampno\"] + 0.2\n",
    "hh_OK[\"UID\"] = hh_OK[\"sampno\"] + 0.2\n",
    "hh_wgt_OK[\"UID\"] = hh_wgt_OK[\"sampno\"] + 0.2\n",
    "veh_OK[\"UID\"] = veh_OK[\"sampno\"] + 0.2\n",
    "per_IA[\"UID\"] = per_IA[\"sampno\"] + 0.3\n",
    "hh_IA[\"UID\"] = hh_IA[\"sampno\"] + 0.3\n",
    "hh_wgt_IA[\"UID\"] = hh_wgt_IA[\"sampno\"] + 0.3\n",
    "veh_IA[\"UID\"] = veh_IA[\"sampno\"] + 0.3\n",
    "per_CA[\"UID\"] = per_CA[\"sampno\"] + 0.4\n",
    "hh_CA[\"UID\"] = hh_CA[\"sampno\"] + 0.4\n",
    "hh_wgt_CA[\"UID\"] = hh_wgt_CA[\"sampno\"] + 0.4\n",
    "veh_CA[\"UID\"] = veh_CA[\"sampno\"] + 0.4\n",
    "per_AZ[\"UID\"] = per_AZ[\"sampno\"] + 0.5\n",
    "hh_AZ[\"UID\"] = hh_AZ[\"sampno\"] + 0.5\n",
    "hh_wgt_AZ[\"UID\"] = hh_wgt_AZ[\"sampno\"] + 0.5\n",
    "veh_AZ[\"UID\"] = veh_AZ[\"sampno\"] + 0.5\n",
    "per_WI[\"UID\"] = per_WI[\"sampno\"] + 0.6\n",
    "hh_WI[\"UID\"] = hh_WI[\"sampno\"] + 0.6\n",
    "hh_wgt_WI[\"UID\"] = hh_wgt_WI[\"sampno\"] + 0.6\n",
    "veh_WI[\"UID\"] = veh_WI[\"sampno\"] + 0.6\n",
    "\n",
    "loc_all = pd.concat([loc_GA,loc_OK,loc_IA,loc_CA,loc_AZ,loc_WI])\n",
    "per_all = pd.concat([per_GA,per_OK,per_IA,per_CA,per_AZ,per_WI])\n",
    "hh_all = pd.concat([hh_GA,hh_OK,hh_IA,hh_CA,hh_AZ,hh_WI])\n",
    "veh_all = pd.concat([veh_GA,veh_OK,veh_IA,veh_CA,veh_AZ,veh_WI])\n",
    "hh_wgt_all = pd.concat([hh_wgt_GA,hh_wgt_OK,hh_wgt_IA,hh_wgt_CA,hh_wgt_AZ,hh_wgt_WI])\n",
    "\n",
    "loc_all.to_csv(\"../Data/loc_all.csv\",index=False)\n",
    "per_all.to_csv(\"../Data/per_all.csv\",index=False)\n",
    "hh_all.to_csv(\"../Data/hh_all.csv\",index=False)\n",
    "hh_wgt_all.to_csv(\"../Data/hh_wgt_all.csv\",index=False)\n",
    "veh_all.to_csv(\"../Data/veh_all.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dc1c7-9ebf-4ae2-93c4-06458cce935e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
